package tpp;

import java.util.*;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.*;
//import java.net.URI;

public class TPP {

	public static final int PARTS_NUM = 4;
	// try different value to get the best performance.

	public static int hashFun(String nodeName) {
		int shit = nodeName.hashCode() % PARTS_NUM;
		if (shit < 0) {
			shit += PARTS_NUM;
		}
		return shit;
	}

	public static class TppMapper extends Mapper<LongWritable, Text, Text, Text> {

		public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
			String[] strs = value.toString().split(" ");
			assert (strs.length == 2);
			String u = strs[0];
			String v = strs[1];
			int hu = hashFun(u);
			int hv = hashFun(v);
			for (int a = 0; a <= PARTS_NUM - 2; a++) {
				for (int b = a + 1; b <= PARTS_NUM - 1; b++) {
					if ((hu == a || hu == b) && (hv == a || hv == b)) {
						// we use different symbols to mark them.
						context.write(new Text(a + "%" + b), new Text(u + "#" + v));
					}
				}
			}
			if (hu != hv) {
				for (int a = 0; a <= PARTS_NUM - 3; a++) {
					for (int b = a + 1; b <= PARTS_NUM - 2; b++) {
						for (int c = b + 1; c <= PARTS_NUM - 1; c++) {
							if ((hu == a || hu == b || hu == c) && (hv == a || hv == b || hv == c)) {
								context.write(new Text(a + "%" + b + "%" + c), new Text(u + "#" + v));
							}
						}
					}
				}
			}
		}
	}

	public static class TppReducer extends Reducer<Text, Text, Text, IntWritable> {
		
/*		
		private static HashMap<String, Integer> nodeDeg = new HashMap<String, Integer>();
		private static Path localFiles = null;

		public void setup(Context context) throws IOException, InterruptedException {
			URI[] cacheFile = context.getCacheFiles();
			localFiles = new Path(cacheFile[0]);
			String line;
			BufferedReader br = new BufferedReader(new FileReader(localFiles.toString()));
			while ((line = br.readLine()) != null) {
				String[] strs = line.split("#");
				if (strs.length != 2) {
					System.err.println(line);
				} else {
					nodeDeg.put(strs[0], Integer.parseInt(strs[1]));
				}
			}
			br.close();
		}
*/
		public void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {
			Map<String, Set<String>> G = new TreeMap<String, Set<String>>();
			for (Text e : values) {
				String[] strs = e.toString().split("#");
				String u = strs[0];
				String v = strs[1];
				if (!G.containsKey(u)) {
					G.put(u, new TreeSet<String>());
				}
				if (!G.containsKey(v)) {
					G.put(v, new TreeSet<String>());
				}
/*				
				if (nodeDeg.get(u) < nodeDeg.get(v)) {
					G.get(u).add(v);
				} else if (nodeDeg.get(u) > nodeDeg.get(v)) {
					G.get(v).add(u);
				} else
*/ 
				if (u.hashCode() < v.hashCode()) {
					G.get(u).add(v);
				} else if (u.hashCode() > v.hashCode()) {
					G.get(v).add(u);
				} else if (u.compareTo(v) < 0){
					G.get(u).add(v);
				} else if (u.compareTo(v) > 0){
					G.get(v).add(u);
				} else {
					System.out.println("single circle");
				}
			}
			//triangle count in G
			int hs, ht, hv, num = 0, weakNum = 0;
			for (Map.Entry<String, Set<String>> entry : G.entrySet()) {
				hs = hashFun(entry.getKey());
				for (String t : entry.getValue()) {
					ht = hashFun(t);
					Set<String> intersection = new TreeSet<String>(entry.getValue());
					intersection.retainAll(G.get(t));
					for (String v : intersection) {
						hv = hashFun(v);
						if (hs == ht && ht == hv) {
							weakNum++;
						} else {
							num++;
						}
					}
				}
			}
			Configuration conf = context.getConfiguration();
			conf.setInt("num", conf.getInt("num", 0) + num);
			conf.setInt("weakNum", conf.getInt("weakNum", 0) + weakNum);
		}
		
		public void cleanup(Context context) throws IOException, InterruptedException {
			Configuration conf = context.getConfiguration();
			int num = conf.getInt("num", 0);
			int weakNum = conf.getInt("weakNum", 0);
			context.write(new Text("Nums:"), new IntWritable(num));
			context.write(new Text("WeakNums:"), new IntWritable(weakNum));
			int trianglesNum = num + weakNum / (PARTS_NUM - 1);
			context.write(new Text("Triangle Nums:"), new IntWritable(trianglesNum));
		}
	}

	public static void main(String[] args) throws Exception {
		Configuration conf = new Configuration();
		Job job1 = Job.getInstance(conf, "TPP");
//		job1.addCacheFile(new Path("gplus_combined.unique.txt.degree").toUri());
//		job1.addCacheFile(new Path("twitter_graph_v2.txt.degree").toUri());
		job1.setJarByClass(TPP.class);
		job1.setOutputKeyClass(Text.class);
		job1.setOutputValueClass(Text.class);
		job1.setMapperClass(TppMapper.class);
		job1.setReducerClass(TppReducer.class);
		// TPP4 use C4,2+C4,3=10 reducers
		job1.setNumReduceTasks(10);
		FileInputFormat.addInputPath(job1, new Path(args[0]));
		FileOutputFormat.setOutputPath(job1, new Path(args[1]));
		job1.waitForCompletion(true);
	}

}